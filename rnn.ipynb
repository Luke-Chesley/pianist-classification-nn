{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "import glob\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 2500)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Preprocessing function with librosa\n",
    "N_BINS = 60\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "\n",
    "def get_logC(audio_file):\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    C = librosa.cqt(\n",
    "        y, sr=sr, fmin=librosa.note_to_hz(\"C1\"), n_bins=N_BINS, hop_length=HOP_LENGTH\n",
    "    )\n",
    "    logC = librosa.amplitude_to_db(np.abs(C))\n",
    "    df = pd.DataFrame(logC)\n",
    "    return df\n",
    "\n",
    "\n",
    "### Accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = correct / len(y_true) * 100\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "### Batch function\n",
    "\n",
    "\n",
    "def split_batches(x, batch_size):\n",
    "    return torch.split(x, batch_size)\n",
    "\n",
    "\n",
    "### dict function\n",
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "\n",
    "\n",
    "### set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "### get audio files\n",
    "audio_files = glob.glob(\"audio_files/**/*.mp3\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign classes\n",
    "\n",
    "artist_dict = {\n",
    "    \"Gould\": 0,\n",
    "    \"Ishizaka\": 1,\n",
    "    \"Richter\": 2,\n",
    "    \"Schiff\": 3,\n",
    "    \"Tureck\": 4,\n",
    "    \"Tharaud\": 5,\n",
    "    \"Moravec\": 6,\n",
    "    \"Rubinstein\": 7,\n",
    "    \"Pogorelich\": 8,\n",
    "    \"Nikolayeva\": 9,\n",
    "    \"Horowitz\": 10,\n",
    "    \"Crochet\": 11,\n",
    "}\n",
    "\n",
    "for n in audio_files[0:]:\n",
    "    artist = n.split(\"/\")[1].split()[0]\n",
    "    if artist not in artist_dict.keys():\n",
    "        print(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get data\n",
    "\n",
    "SECONDS_PER_SAMPLE = 10\n",
    "chunk_size = SECONDS_PER_SAMPLE * 45  # 45 samples per second\n",
    "X_list = []  # List to store X arrays\n",
    "y_list = []  # List to store y arrays\n",
    "\n",
    "for file in audio_files[0:]:\n",
    "    t = get_logC(file)\n",
    "\n",
    "    artist_mapping = file.split(\"/\")[1].split()[0]\n",
    "\n",
    "    array_list = []\n",
    "\n",
    "    for n in range(len(t.columns) // chunk_size):\n",
    "        arr = t[range(n * chunk_size, (n + 1) * chunk_size, 1)].T.to_numpy()\n",
    "        array_list.append(arr)\n",
    "\n",
    "    arrays = np.array(array_list)\n",
    "    X_list.append(torch.tensor(arrays))\n",
    "    y_list.append(torch.full((arrays.shape[0],), artist_dict[artist_mapping]))\n",
    "\n",
    "X = torch.cat(X_list, dim=0)\n",
    "y = torch.cat(y_list, dim=0)\n",
    "y = y.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7410, 450, 60]), torch.Size([7410]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(X, \"X.pt\")\n",
    "# torch.save(y, \"y.pt\")\n",
    "\n",
    "X = torch.load(\"X.pt\")\n",
    "y = torch.load(\"y.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7410, 450, 60]), torch.Size([7410]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(torch.unique(y))\n",
    "identity_matrix = torch.eye(num_classes)\n",
    "\n",
    "one_hot_encoded = identity_matrix[y.to(torch.int64)]\n",
    "\n",
    "y = one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[2], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "INPUT_SIZE = X_train.shape[2]\n",
    "HIDDEN_SIZE = 12\n",
    "OUTPUT_SIZE = y_train.shape[1]\n",
    "\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # This just calls the base class constructor\n",
    "        super().__init__()\n",
    "        # Neural network layers assigned as attributes of a Module subclass\n",
    "        # have their parameters registered for training automatically.\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            INPUT_SIZE, HIDDEN_SIZE, nonlinearity=\"relu\", batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear = torch.nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The RNN also returns its hidden state but we don't use it.\n",
    "        # While the RNN can also take a hidden state as input, the RNN\n",
    "        # gets passed a hidden state initialized with zeros by default.\n",
    "        h = self.rnn(x)[0]\n",
    "        x = self.linear(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = SimpleRNN().to(device)\n",
    "\n",
    "# model_1 = torch.compile(model_1)\n",
    "\n",
    "# loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# optimizer\n",
    "\n",
    "# optimizer = torch.optim.SGD(model_1.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.RMSprop(model_1.parameters(), lr=0.001)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# set number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# put data on device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_num_batches = len(X_train) // BATCH_SIZE\n",
    "test_batch = 0\n",
    "\n",
    "X_train_batches = split_batches(X_train, BATCH_SIZE)\n",
    "\n",
    "y_train_batches = split_batches(y_train, BATCH_SIZE)\n",
    "\n",
    "X_test_batches = split_batches(X_test, BATCH_SIZE)\n",
    "\n",
    "y_test_batches = split_batches(y_test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 2.16442 | Train Acc: 37.5% | Test Loss: 1.96553 | Test Acc: 37.5%\n",
      "Epoch: 10 | Train Loss: 1.06949 | Train Acc: 62.5% | Test Loss: 1.75715 | Test Acc: 37.5%\n",
      "Epoch: 20 | Train Loss: 0.92192 | Train Acc: 75.0% | Test Loss: 1.08574 | Test Acc: 75.0%\n",
      "Epoch: 30 | Train Loss: 1.03677 | Train Acc: 75.0% | Test Loss: 1.41016 | Test Acc: 50.0%\n",
      "Epoch: 40 | Train Loss: 2.12544 | Train Acc: 25.0% | Test Loss: 1.17906 | Test Acc: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Build training and evaluation loops\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in range(train_num_batches):\n",
    "        X_train_batch = X_train_batches[batch]\n",
    "\n",
    "        y_train_batch = y_train_batches[batch]\n",
    "\n",
    "        model_1.train()\n",
    "\n",
    "        y_logits = model_1(X_train_batch)\n",
    "\n",
    "        y_logits = y_logits[:, -1, :]\n",
    "\n",
    "        # print(y_logits.shape)\n",
    "\n",
    "        y_pred = torch.argmax(sigmoid(torch.softmax(y_logits, dim=1)), dim=1)\n",
    "\n",
    "        # print(y_pred.shape)\n",
    "\n",
    "        y_train_batch = torch.argmax(y_train_batch, dim=1)\n",
    "\n",
    "        loss = loss_fn(y_logits, y_train_batch)\n",
    "\n",
    "        acc = f1_score(y_true=y_train_batch.cpu(), y_pred=y_pred.cpu(), average=\"micro\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # test\n",
    "    if batch % 4 == 0:\n",
    "        test_batch += 1\n",
    "\n",
    "        model_1.eval()\n",
    "        with torch.inference_mode():\n",
    "            y_test_logits = model_1(X_test_batches[test_batch])\n",
    "\n",
    "            y_test_logits = y_test_logits[:, -1, :]\n",
    "\n",
    "            y_test_pred = torch.argmax(\n",
    "                sigmoid(torch.softmax(y_test_logits, dim=1)), dim=1\n",
    "            )\n",
    "\n",
    "            y_test_true = torch.argmax(y_test_batches[test_batch], dim=1)\n",
    "\n",
    "            test_loss = loss_fn(y_test_logits, y_test_true)\n",
    "\n",
    "            test_acc = f1_score(\n",
    "                y_true=y_test_true.cpu(), y_pred=y_test_pred.cpu(), average=\"micro\"\n",
    "            )\n",
    "\n",
    "    if (epoch) % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Train Loss: {loss:.5f} | Train Acc: {acc*100:.1f}% | Test Loss: {test_loss:.5f} | Test Acc: {test_acc*100:.1f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1482, 12])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 1, 4, 5, 7, 7, 7, 0], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  6,  7, 11,  8,  6,  4,  4], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 11,  2,  0,  5,  6,  8,  4], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is: Moravec(6), True is: Rubinstein(7)\n",
      "Guess is: Crochet(11), True is: Nikolayeva(9)\n",
      "Guess is: Tureck(4), True is: Gould(0)\n",
      "Guess is: Rubinstein(7), True is: Moravec(6)\n",
      "Guess is: Tureck(4), True is: Crochet(11)\n",
      "Guess is: Moravec(6), True is: Pogorelich(8)\n"
     ]
    }
   ],
   "source": [
    "SECONDS_PER_SAMPLE = 10\n",
    "chunk_size = SECONDS_PER_SAMPLE * 45  # 45 samples per second\n",
    "\n",
    "\n",
    "files = [\n",
    "    \"test_audio/Rubinstein - Chopin Nocturne Op. 48 in C Minor.mp3\",\n",
    "    \"test_audio/Nikolayeva - Shostakovich  P and F B2.mp3\",\n",
    "    \"test_audio/Gould - Goldberg Variations, Aria.mp3\",\n",
    "    \"test_audio/Moravec - Bach Chromatic Fantasia BVW 903.mp3\",\n",
    "    \"test_audio/Crochet - Goldberg Variation.mp3\",\n",
    "    \"test_audio/Pogorelich - Chopin 4 scherzi.mp3\",\n",
    "]\n",
    "for file in files:\n",
    "    t = get_logC(file)\n",
    "    X_list = []  # List to store X arrays\n",
    "    y_list = []  # List to store y arrays\n",
    "\n",
    "    artist_mapping = file.split(\"/\")[1].split()[0]\n",
    "\n",
    "    array_list = []\n",
    "\n",
    "    for n in range(len(t.columns) // chunk_size):\n",
    "        arr = t[range(n * chunk_size, (n + 1) * chunk_size, 1)].T.to_numpy()\n",
    "        array_list.append(arr)\n",
    "\n",
    "    arrays = np.array(array_list)\n",
    "    X_list.append(torch.tensor(arrays))\n",
    "    y_list.append(torch.full((arrays.shape[0],), artist_dict[artist_mapping]))\n",
    "\n",
    "    x_test_1 = torch.cat(X_list, dim=0)\n",
    "    y_test_1 = torch.cat(y_list, dim=0)\n",
    "    x_test_1 = x_test_1.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_1_logits = model_1(x_test_1)\n",
    "\n",
    "        test_1_logits = test_1_logits[:, -1, :]\n",
    "\n",
    "        test_1_preds = torch.argmax(sigmoid(torch.softmax(test_1_logits, dim=1)), dim=1)\n",
    "\n",
    "        test_1_pred = torch.mode(\n",
    "            torch.argmax(sigmoid(torch.softmax(test_1_logits, dim=1)), dim=1)\n",
    "        ).values\n",
    "\n",
    "    print(\n",
    "        f\"Guess is: {get_keys_from_value(artist_dict, pd.Series(test_1_pred.cpu()).value_counts().index[0] )[0]}({pd.Series(test_1_pred.cpu()).value_counts().index[0]}), True is: {get_keys_from_value(artist_dict, pd.Series(y_test_1)[0])[0]}({pd.Series(y_test_1)[0]})\"\n",
    "    )\n",
    "\n",
    "    pd.Series(test_1_preds.cpu()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is: Moravec(6), True is: Pogorelich(8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6     89\n",
       "1     46\n",
       "7     34\n",
       "11    16\n",
       "10    13\n",
       "2     10\n",
       "0     10\n",
       "4     10\n",
       "5      8\n",
       "8      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6, device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
